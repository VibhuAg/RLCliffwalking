{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\"Blackjack-v1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Action Space:\n",
    "\n",
    "There are two actions: stick (0), and hit (1).\n",
    "\n",
    "Observation Space:\n",
    "\n",
    "The observation consists of a 3-tuple containing: the player’s current sum, \n",
    "the value of the dealer’s one showing card (1-10 where 1 is ace), and whether\n",
    "the player holds a usable ace (0 or 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Below is shit copied from past homeworks\n",
    "\n",
    "# Homework 2\n",
    "\n",
    "def get_policy(values, gamma, policy):\n",
    "  for s in range(env.observation_space.n): \n",
    "    q = np.zeros(env.action_space.n)\n",
    "\n",
    "    for a in range(env.action_space.n): \n",
    "      for neighbor in env.env.P[s][a]:\n",
    "        prob, s_prime, reward, _ = neighbor\n",
    "        q[a] += (prob * (reward + gamma * values[s_prime]))\n",
    "\n",
    "    policy[s] = np.argmax(q)\n",
    "    \n",
    "  return policy\n",
    "\n",
    "# iterates on values 1000 times\n",
    "def value_iteration(values, gamma): \n",
    "\n",
    "  for i in range(1000): \n",
    "    old_vals = np.copy(values)\n",
    "\n",
    "    for s in range(env.observation_space.n): \n",
    "\n",
    "      action_value = []\n",
    "\n",
    "      for a in range(env.action_space.n): \n",
    "\n",
    "        expected_reward = 0\n",
    "        expected_value = 0\n",
    "\n",
    "        for neighbor in env.env.P[s][a]:\n",
    "          prob, s_prime, reward, _ = neighbor\n",
    "\n",
    "          expected_reward += reward * prob\n",
    "          expected_value += old_vals[s_prime] * prob\n",
    "\n",
    "          action_value += [expected_reward + (gamma * expected_value)]\n",
    "      \n",
    "      values[s] = max(action_value)\n",
    "    \n",
    "  return values\n",
    "\n",
    "gamma = 1\n",
    "values = np.zeros(env.observation_space.n)\n",
    "policy = np.zeros(env.observation_space.n)\n",
    "\n",
    "values = value_iteration(values, gamma)\n",
    "policy = get_policy(values, gamma, policy)\n",
    "\n",
    "total_reward = 0\n",
    "\n",
    "for i in range(1000):\n",
    "\tobs = env.reset()\n",
    "\n",
    "\twhile True:\n",
    "\t\taction = policy[obs]\n",
    "\t\tobs, reward, done, info = env.step(action)\n",
    "\t\t\n",
    "\t\tif done:\n",
    "\t\t\ttotal_reward += reward\n",
    "\t\t\tbreak\n",
    "      \n",
    "print(\"Average reward: \", total_reward / 1000.0)\n",
    "\n",
    "\n",
    "# Homework 3\n",
    "\n",
    "obs = env.reset()\n",
    "values = [0.5,0.5,0.5,0.5,0.5,0,0.5,0,0.5,0.5,0.5,0,0,0.5,0.5,1]\n",
    "alpha = 1\n",
    "gamma = 1\n",
    "\n",
    "# runs 10000 episodes\n",
    "for i in range(10000): \n",
    "  done = False\n",
    "  state = 0\n",
    "\n",
    "  while True: \n",
    "    \n",
    "    # get random action\n",
    "    action = env.action_space.sample()\n",
    "\n",
    "    # R, s’ ← take action given by policy(current state)\n",
    "    s_, r, done, _ = env.step(action)\n",
    "\n",
    "    # v(s) ← v(s) + α * (R + γ*v(s’) - v(s))\n",
    "    values[state] += alpha * (r + gamma * values[s_] - values[state])\n",
    "\n",
    "    # s ← s’\n",
    "    state = s_\n",
    "\n",
    "    if done: \n",
    "      break\n",
    "      clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'BlackjackEnv' object has no attribute 'P'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_32832/748461630.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0ma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0ms\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mP\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'BlackjackEnv' object has no attribute 'P'"
     ]
    }
   ],
   "source": [
    "a = 1\n",
    "s = 2\n",
    "env.env.P[s][a]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Steps for policy iteration\n",
    "# 1. Start with random policy\n",
    "# 2. Update values of every state with Bellman expectation equation\n",
    "# 3. Find new optimal policy be acting greedily on state values\n",
    "def get_policy(values, gamma, policy):\n",
    "  for s in range(len(env.observation_space)): \n",
    "    \n",
    "    # Action space is either 0 or 1\n",
    "    q = np.zeros(2)\n",
    "\n",
    "    for a in range(2): \n",
    "      for neighbor in env.env.P[s][a]:\n",
    "        prob, s_prime, reward, _ = neighbor\n",
    "        q[a] += (prob * (reward + gamma * values[s_prime]))\n",
    "\n",
    "    policy[s] = np.argmax(q)\n",
    "    \n",
    "  return policy\n",
    "\n",
    "# iterates on values 1000 times\n",
    "def value_iteration(values, gamma): \n",
    "\n",
    "  for i in range(1000): \n",
    "    old_vals = np.copy(values)\n",
    "\n",
    "    for s in range(env.observation_space.n): \n",
    "\n",
    "      action_value = []\n",
    "\n",
    "      for a in range(env.action_space.n): \n",
    "\n",
    "        expected_reward = 0\n",
    "        expected_value = 0\n",
    "\n",
    "        for neighbor in env.env.P[s][a]:\n",
    "          prob, s_prime, reward, _ = neighbor\n",
    "\n",
    "          expected_reward += reward * prob\n",
    "          expected_value += old_vals[s_prime] * prob\n",
    "\n",
    "          action_value += [expected_reward + (gamma * expected_value)]\n",
    "      \n",
    "      values[s] = max(action_value)\n",
    "    \n",
    "  return values\n",
    "\n",
    "gamma = 1\n",
    "values = np.zeros(env.observation_space.n)\n",
    "policy = np.zeros(env.observation_space.n)\n",
    "\n",
    "values = value_iteration(values, gamma)\n",
    "policy = get_policy(values, gamma, policy)\n",
    "\n",
    "total_reward = 0\n",
    "\n",
    "for i in range(1000):\n",
    "\tobs = env.reset()\n",
    "\n",
    "\twhile True:\n",
    "\t\taction = policy[obs]\n",
    "\t\tobs, reward, done, info = env.step(action)\n",
    "\t\t\n",
    "\t\tif done:\n",
    "\t\t\ttotal_reward += reward\n",
    "\t\t\tbreak\n",
    "      \n",
    "print(\"Average reward: \", total_reward / 1000.0)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('CliffWalking-v0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1.0, 1, -1, False)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.env.P[13][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  C  C  C  C  C  C  C  C  C  C  T\n",
      "\n"
     ]
    }
   ],
   "source": [
    "env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stop here\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "x  C  C  C  C  C  C  C  C  C  C  T\n",
      "\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "o  o  o  o  o  o  o  o  o  o  o  o\n",
      "x  C  C  C  C  C  C  C  C  C  C  T\n",
      "\n",
      "stop here"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_25764/1230465865.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[0mpolicy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobservation_space\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 45\u001b[1;33m \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue_iteration\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     46\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[0mpolicy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_policy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgamma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpolicy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_25764/1230465865.py\u001b[0m in \u001b[0;36mvalue_iteration\u001b[1;34m(values, gamma)\u001b[0m\n\u001b[0;32m     22\u001b[0m       \u001b[0maction_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0ms\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m34\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"stop here\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m       \u001b[1;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maction_space\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\ipykernel\\iostream.py\u001b[0m in \u001b[0;36mwrite\u001b[1;34m(self, string)\u001b[0m\n\u001b[0;32m    527\u001b[0m             \u001b[0mis_child\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_master_process\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    528\u001b[0m             \u001b[1;31m# only touch the buffer in the IO thread to avoid races\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 529\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpub_thread\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mschedule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_buffer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    530\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_child\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    531\u001b[0m                 \u001b[1;31m# mp.Pool cannot be trusted to flush promptly (or ever),\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\ipykernel\\iostream.py\u001b[0m in \u001b[0;36mschedule\u001b[1;34m(self, f)\u001b[0m\n\u001b[0;32m    212\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_events\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    213\u001b[0m             \u001b[1;31m# wake event thread (message content is ignored)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 214\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_event_pipe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mb''\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    215\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    216\u001b[0m             \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\zmq\\sugar\\socket.py\u001b[0m in \u001b[0;36msend\u001b[1;34m(self, data, flags, copy, track, routing_id, group)\u001b[0m\n\u001b[0;32m    539\u001b[0m                 )\n\u001b[0;32m    540\u001b[0m             \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroup\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgroup\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 541\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mSocket\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mflags\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrack\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    542\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    543\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0msend_multipart\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmsg_parts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.send\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.send\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket._send_copy\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\zmq\\backend\\cython\\checkrc.pxd\u001b[0m in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def get_policy(values, gamma, policy):\n",
    "  for s in range(env.observation_space.n): \n",
    "    q = np.zeros(env.action_space.n)\n",
    "\n",
    "    for a in range(env.action_space.n): \n",
    "      for neighbor in env.env.P[s][a]:\n",
    "        prob, s_prime, reward, _ = neighbor\n",
    "        q[a] += (prob * (reward + gamma * values[s_prime]))\n",
    "\n",
    "    policy[s] = np.argmax(q)\n",
    "    \n",
    "  return policy\n",
    "\n",
    "# iterates on values 1000 times\n",
    "def value_iteration(values, gamma): \n",
    "\n",
    "  for i in range(100): \n",
    "    old_vals = np.copy(values)\n",
    "\n",
    "    for s in range(env.observation_space.n): \n",
    "\n",
    "      action_value = []\n",
    "      if s == 34:\n",
    "        print(\"stop here\")\n",
    "      for a in range(env.action_space.n): \n",
    "\n",
    "        expected_reward = 0\n",
    "        expected_value = 0\n",
    "        neighbor = env.env.P[s][a]\n",
    "        prob, s_prime, reward, _ = neighbor[0]\n",
    "\n",
    "        expected_reward += reward\n",
    "        expected_value += old_vals[s_prime] * prob\n",
    "\n",
    "        action_value += [expected_reward + (gamma * expected_value)]\n",
    "      \n",
    "      values[s] = max(action_value)\n",
    "    \n",
    "  return values\n",
    "\n",
    "gamma = 0.7\n",
    "values = np.zeros(env.observation_space.n)\n",
    "policy = np.zeros(env.observation_space.n)\n",
    "\n",
    "values = value_iteration(values, gamma)\n",
    "print(values)\n",
    "policy = get_policy(values, gamma, policy)\n",
    "print(policy)\n",
    "total_reward = 0\n",
    "\n",
    "for i in range(1):\n",
    "    obs = env.reset()\n",
    "\n",
    "    while True:\n",
    "        action = policy[obs]\n",
    "        print(action)\n",
    "        obs, reward, done, info = env.step(action)\n",
    "\n",
    "        if done:\n",
    "            total_reward += reward\n",
    "            break\n",
    "      \n",
    "print(\"Average reward: \", total_reward / 1.0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "q_table = np.zeros(([env.observation_space.n, env.action_space.n]))\n",
    "alpha = 0.5\n",
    "gamma = 0.9\n",
    "all_rewards = []\n",
    "for i in range(100):\n",
    "    old_obs = 36\n",
    "    env.reset()\n",
    "    total_reward = 0\n",
    "    while True:\n",
    "        max_action = np.argmax(q_table[old_obs, :])\n",
    "        obs, reward, done, info = env.step(max_action)\n",
    "        total_reward += reward\n",
    "        action_prime = np.argmax(q_table[obs, :])\n",
    "        q_table[old_obs, max_action] += alpha*(reward + gamma*(q_table[obs, action_prime]- q_table[old_obs, max_action]))\n",
    "        old_obs = obs\n",
    "        if done:\n",
    "            break\n",
    "    all_rewards.append(total_reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "x = np.arange(1, 101)\n",
    "y = np.array(all_rewards)\n",
    "\n",
    "plt.title(\"Reward graph over 100 iterations\")\n",
    "plt.xlabel(\"X axis\")\n",
    "plt.ylabel(\"Y axis\")\n",
    "plt.plot(x, y, color =\"red\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2be5faf79681da6f2a61fdfdd5405d65d042280f7fba6178067603e3a2925119"
  },
  "kernelspec": {
   "display_name": "Python 3.10.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
